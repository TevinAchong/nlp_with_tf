{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_with_tf_c2_3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ageuUEij4h0g",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network-related operations\n",
        "### Nonlinear activations used by neural networks\n",
        "* Typically there is a nonlinear activation transformation (activation layer) after each layer output in a neural network (except for the last layer).\n",
        "* Nonlinear transformation helps a neural network to learn various nonlinear patterns that are present in data. \n",
        "* Commonly used nonlinear activation functions:\n",
        "1. `tf.nn.sigmoid(x, name=None)` \n",
        "\n",
        "`sigmoid(x) = 1/(1+exp(x))`\n",
        "\n",
        "2. `tf.nn.relu(x, name=None)`\n",
        "\n",
        "`relu(x) = max(0, x)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GANYDdJ06LYF",
        "colab_type": "text"
      },
      "source": [
        "# The Convolution Operation\n",
        "* Convolution is used to produce different effects on images. \n",
        "* Achieved by shifting a convolution filter on top of an image to produce a different output at each location. \n",
        "* At each location, do element-wise multiplication of the elements in the convolution filter with the image patch (same size as convolution filter) that overlaps with the convolution filter and takes the sum of the multiplication. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBR3zIgd6-KQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "df21b399-5256-496c-f870-fbd4d192abb1"
      },
      "source": [
        "# Implementation of the convolution operation\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "x = tf.constant(\n",
        "    [[\n",
        "      [[1], [2], [3], [4]],\n",
        "      [[4], [3], [2], [1]],\n",
        "      [[5], [6], [7], [8]],\n",
        "      [[8], [7], [6], [5]]\n",
        "    ]],\n",
        "    dtype=tf.float32\n",
        ")\n",
        "\n",
        "x_filter = tf.constant(\n",
        "    [\n",
        "     [\n",
        "      [[0.5]], [[1]]\n",
        "     ],\n",
        "     [\n",
        "      [[0.5]], [[1]]\n",
        "     ]\n",
        "    ],\n",
        "    dtype=tf.float32\n",
        ")\n",
        "\n",
        "x_stride = [1, 1, 1, 1]\n",
        "x_padding = 'VALID'\n",
        "\n",
        "x_conv = tf.nn.conv2d(\n",
        "    input=x, filter=x_filter,\n",
        "    strides=x_stride, padding=x_padding\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOn_me8z8Iqg",
        "colab_type": "text"
      },
      "source": [
        "The `tf.conv2d(...)` operation requires `input, filter` and `stride` to be of an exact format.\n",
        "\n",
        "The arguments of `tf.nn.conv2d(input, filter, strides, padding)`:\n",
        "* **input**: Typically a 4D tensor where the dimensions should be ordered as `[batch_size, height, width, channels]`.\n",
        "    * **batch_size**: amount of data (e.g. inputs like images and words) in a single batch of data. Normally process data in batches as large datasets are usually used. At a given training step, we randomly sample a small batch of data that approximately represents the whole dataset. Doing this for many steps allows us to approximate the full dataset. \n",
        "    * **height and width**: Height and width of the input\n",
        "    * **channels**: Depth of an input (e.g. for an RGB image the channels will be 3 - a channel for each color)\n",
        "* **filter**: 4D tensor that represents the convolution of the window of the operation operation. Filter dimensions should be `[height, width, in_channels, out_channels]`:\n",
        "    * **height and width**: height and width of the filter (often smaller than the input).\n",
        "    * **in_channels**: Number of channels of the input to the layer\n",
        "    * **out_channels**: Number of channels to be produced in the output of the layer\n",
        "* **strides**: List with four elements `[batch_stride, height_stride, width_stride, channels_stride]`. Denotes how many elements to skip during a single shift of the convolution window on the input. \n",
        "* **padding**: Can be one of `[SAME, VALID]`. Decides how to handle the convolution operation near the boundaries of the input. \n",
        "    * `VALID` performs the convolution without padding. If we convolve an input of *n* length with a convolution of size *h*, this will result in an output of size *(n-h+1 < n)*. Diminishing output size can limit the depth of neural networks. \n",
        "    * `SAME` pads zeros to the boundary such that the output will have the same height and width as the input.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCfcXJ_1AuOv",
        "colab_type": "text"
      },
      "source": [
        "# The pooling operation\n",
        "* Behaves similar to the convolution operation.\n",
        "* Except, we output the maximum element of the image patch for that location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suFnXQZSBNyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pooling operation\n",
        "x = tf.constant(\n",
        "    [[\n",
        "      [[1], [2], [3], [4]],\n",
        "      [[4], [3], [2], [1]],\n",
        "      [[5], [6], [7], [8]],\n",
        "      [[8], [7], [6], [5]]\n",
        "    ]],\n",
        "    dtype=tf.float32\n",
        ")\n",
        "\n",
        "x_ksize = [1, 2, 2, 1]\n",
        "x_stride = [1, 2, 2, 1]\n",
        "x_padding = 'VALID'\n",
        "\n",
        "x_pool = tf.nn.max_pool(\n",
        "    value=x, ksize=x_ksize,\n",
        "    strides=x_stride, padding=x_padding\n",
        ")\n",
        "\n",
        "# Returns:\n",
        "# [[[\n",
        "#   [4]\n",
        "#   [4.]],\n",
        "#   [[8.]\n",
        "#   [8.]]\n",
        "# ]]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKGaNexZCoRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}